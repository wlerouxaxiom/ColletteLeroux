export const articles = [
  {
    id: 1,
    slug: 'ontario-ohsa-quiet-changes',
    title: 'The Quiet Changes to Ontario\'s OHSA That Every Manufacturer Needs to Know',
    category: 'Regulatory Shifts',
    date: 'February 18, 2026',
    readTime: '8 min read',
    excerpt: 'Recent amendments to Ontario\'s Occupational Health and Safety Act have introduced subtle but significant shifts in compliance requirements. Here\'s what changed and what it means for your operation.',
    body: [
      { type: 'paragraph', text: 'Most regulatory changes arrive with fanfare. Press releases, industry alerts, compliance webinars. But some of the most consequential shifts happen quietly — buried in omnibus bills, tucked into technical amendments, or rolled out through updated Ministry guidelines with minimal notice.' },
      { type: 'paragraph', text: 'That\'s what happened with Ontario\'s OHSA this past year. While the headline reforms focused on mental health and workplace harassment provisions, several technical amendments to sections 25, 27, and 28 have quietly redefined what "reasonable precautions" means in practice.' },
      { type: 'heading', text: 'What Changed' },
      { type: 'paragraph', text: 'The amendments expand the definition of "competent person" in specific contexts, raise the bar for documented risk assessments in high-risk environments, and clarify employer obligations around worker refusals tied to equipment modifications.' },
      { type: 'paragraph', text: 'On paper, these look like minor clarifications. In practice, they shift the burden of proof in Ministry investigations and set a higher standard for what counts as due diligence.' },
      { type: 'heading', text: 'Why It Matters' },
      { type: 'paragraph', text: 'If your operation relies on internally trained supervisors without third-party certification, you may now be in a gray zone. If your hazard assessments are conducted annually rather than per-task or per-change, you may not meet the new threshold. And if your work refusal protocols haven\'t been updated to reflect the new equipment-specific language, you could face scrutiny during an audit.' },
      { type: 'paragraph', text: 'These aren\'t hypothetical concerns. I\'ve already seen two Ministry orders issued under the revised language — both at mid-sized manufacturers who thought they were compliant.' },
      { type: 'heading', text: 'What to Do Now' },
      { type: 'list', items: [
        'Review your competent person designations and training records',
        'Audit your risk assessment documentation for frequency and specificity',
        'Update your work refusal procedures to reflect the new equipment language',
        'Brief your supervisors on the heightened standard for "reasonable precautions"'
      ]},
      { type: 'paragraph', text: 'The law didn\'t change overnight. But the expectations did. And in health and safety, expectations matter more than intentions.' }
    ],
    tags: ['OHSA', 'Compliance', 'Regulatory Updates', 'Ontario']
  },
  {
    id: 2,
    slug: 'ai-on-shop-floor',
    title: 'AI on the Shop Floor: Promise, Peril, and the Questions No One Is Asking',
    category: 'Industry Trends',
    date: 'February 10, 2026',
    readTime: '10 min read',
    excerpt: 'Predictive maintenance, computer vision, real-time risk monitoring — AI is being sold as the future of workplace safety. But are we asking the right questions about accountability, bias, and human judgment?',
    body: [
      { type: 'paragraph', text: 'Every safety conference I attend now has at least three sessions on AI. Predictive maintenance algorithms that catch equipment failures before they happen. Computer vision systems that detect PPE non-compliance in real time. Machine learning models that predict incident risk based on environmental factors.' },
      { type: 'paragraph', text: 'The promise is compelling: fewer accidents, lower costs, data-driven decision-making. The pitch is seductive. But I keep coming back to the same set of uncomfortable questions that no one seems to be asking.' },
      { type: 'heading', text: 'Who\'s Accountable When the Algorithm Gets It Wrong?' },
      { type: 'paragraph', text: 'AI systems make mistakes. Sometimes they\'re small — a false positive that triggers an unnecessary shutdown. Sometimes they\'re catastrophic — a missed hazard that leads to injury or death.' },
      { type: 'paragraph', text: 'When a human supervisor misses a hazard, we know who\'s responsible. When an algorithm does, the accountability diffuses. Is it the vendor? The data scientist who trained the model? The manager who chose to deploy it? The worker who trusted its output?' },
      { type: 'paragraph', text: 'We don\'t have clear answers yet. And until we do, we\'re building systems on shaky ethical ground.' },
      { type: 'heading', text: 'Are We Automating Bias?' },
      { type: 'paragraph', text: 'AI models are trained on historical data. If that data reflects biased enforcement, selective monitoring, or unequal disciplinary practices, the algorithm learns to replicate those patterns.' },
      { type: 'paragraph', text: 'I\'ve seen safety monitoring systems that flag certain demographics more frequently. Not because those workers are less safe, but because the training data captured biased human behavior. The AI didn\'t create the bias — it amplified it, scaled it, and made it invisible.' },
      { type: 'heading', text: 'What Happens to Human Judgment?' },
      { type: 'paragraph', text: 'One of the underappreciated risks of AI in safety is deskilling. When supervisors rely on algorithms to identify hazards, they stop developing the instinct to see them on their own. When maintenance schedules are dictated by predictive models, technicians lose the feel for when something\'s off.' },
      { type: 'paragraph', text: 'AI can be a powerful tool. But if it replaces human judgment rather than augmenting it, we\'re in trouble.' },
      { type: 'heading', text: 'What I\'m Watching' },
      { type: 'paragraph', text: 'I\'m not anti-AI. I\'m pro-accountability. I want to see clear liability frameworks, transparent model auditing, and real safeguards against algorithmic bias. I want to see AI deployed in ways that enhance human judgment, not replace it.' },
      { type: 'paragraph', text: 'Until we get there, I\'m asking questions. And I think you should too.' }
    ],
    tags: ['AI', 'Technology', 'Risk Management', 'Future of Work']
  },
  {
    id: 3,
    slug: 'psychological-safety-leading-indicator',
    title: 'Psychological Safety Isn\'t a Perk — It\'s a Leading Indicator',
    category: 'Best Practices',
    date: 'January 28, 2026',
    readTime: '7 min read',
    excerpt: 'We measure lagging indicators like incident rates and lost time obsessively. But one of the most predictive factors for physical safety is something we barely track: whether workers feel safe speaking up.',
    body: [
      { type: 'paragraph', text: 'Most safety programs are built around lagging indicators. Incident rates, lost-time injuries, near-miss reports. We measure what already happened and try to prevent it from happening again.' },
      { type: 'paragraph', text: 'But what if one of the most predictive factors for physical safety is something we barely track? What if the best leading indicator isn\'t PPE compliance or housekeeping scores, but whether workers feel safe speaking up?' },
      { type: 'heading', text: 'The Link Between Psychological and Physical Safety' },
      { type: 'paragraph', text: 'Psychological safety — the belief that you won\'t be punished or humiliated for raising concerns — is often framed as a soft skill, a "nice-to-have" for team dynamics. But the research is clear: workplaces with high psychological safety have fewer accidents.' },
      { type: 'paragraph', text: 'Why? Because workers who feel safe speaking up report hazards before they cause harm. They stop work when something feels wrong. They ask questions instead of making dangerous assumptions. They challenge shortcuts that put people at risk.' },
      { type: 'paragraph', text: 'In other words, psychological safety enables the behaviors that prevent incidents. It\'s not a perk. It\'s a control.' },
      { type: 'heading', text: 'What It Looks Like in Practice' },
      { type: 'paragraph', text: 'I\'ve worked in facilities where workers would rather take a risk than speak up. Not because they didn\'t know better, but because past experience taught them that raising concerns led to blame, dismissal, or retaliation.' },
      { type: 'paragraph', text: 'I\'ve also worked in facilities where workers routinely stopped production to address hazards — and were thanked for it. Where supervisors asked "What did I miss?" instead of "Why didn\'t you just follow the procedure?"' },
      { type: 'paragraph', text: 'The difference isn\'t the workers. It\'s the culture.' },
      { type: 'heading', text: 'How to Build It' },
      { type: 'paragraph', text: 'You can\'t mandate psychological safety. But you can create the conditions for it:' },
      { type: 'list', items: [
        'Respond to near-misses and work refusals with curiosity, not discipline',
        'Model vulnerability — admit when you don\'t have the answer',
        'Celebrate people who raise concerns, even when it\'s inconvenient',
        'Track whether workers feel comfortable speaking up (not just whether they do)'
      ]},
      { type: 'paragraph', text: 'This isn\'t soft. It\'s strategic. Because the best hazard control in the world is useless if workers don\'t feel safe activating it.' }
    ],
    tags: ['Safety Culture', 'Leadership', 'Behavioral Safety', 'Risk Management']
  }
];

export const categories = {
  'Regulatory Shifts': 'deep-red',
  'Industry Trends': 'ink-navy',
  'Best Practices': 'warm-gray',
  'Risk & Hazards': 'deep-red',
  'Safety Culture': 'warm-gray',
};

export const getCategoryColor = (category) => {
  return categories[category] || 'ink';
};
